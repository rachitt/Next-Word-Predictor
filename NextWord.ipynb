{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md-vDpZjrU-1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKNvLeCSrmEI"
      },
      "outputs": [],
      "source": [
        "file=open(\"Word.txt\",\"r\",encoding = \"utf8\")\n",
        "lines=[]\n",
        "for i in file:\n",
        "  lines.append(i)\n",
        "#conversion of list to string\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTjxzE5ZtXtL"
      },
      "outputs": [],
      "source": [
        "data=\"\"\n",
        "for i in lines:\n",
        "  data=' '.join(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "F3dfsEgvvxq7",
        "outputId": "a7fba113-bd10-4b24-eb42-54499dcef35f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"heart's content; every one was very kind, and she had three compliments. Annie made her sing, and some one said she had a remarkably fine voice; Major Lincoln asked who the fresh little girl, with the beautiful eyes, was; and Mr. Moffat insisted on dancing with her, because she didn't dawdle, but had some spring in her, as he gracefully expressed it. So, altogether, she had a very nice time, till she overheard a bit of a conversation, which disturbed her extremely. She was sitting just inside th\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=data.replace('\\n','').replace('\"','').replace(\"\\ufeff\",'').replace('***','').replace('”','').replace('“','')\n",
        "data=data.split()\n",
        "data=' '.join(data)\n",
        "data[:500]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTUWVcwzzCw_"
      },
      "source": [
        "**Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb8TK6kqwnWm",
        "outputId": "9e65dadf-94d9-4407-cdad-cc1ee29e4d29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1837, 1308, 128, 32, 13, 50, 224, 1, 10, 25, 319, 1838, 1605, 92, 7]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "import pickle\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "pickle.dump(tokenizer,open('aa.pkl','wb'))\n",
        "sequence=tokenizer.texts_to_sequences([data])[0]\n",
        "\n",
        "sequence[:15]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFaO9DWu3iRT",
        "outputId": "ec3807c8-743a-4a93-ea33-9b43f6f61378"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8713"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size=len(tokenizer.word_index)+1\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af0OfgAc4f08"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "sequences=[]\n",
        "n=3\n",
        "for i in range(3,len(sequence)):\n",
        "  words=sequence[i-n:i+1]\n",
        "  sequences.append(words)\n",
        "sequences=np.array(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luv1s2hj6OvO"
      },
      "outputs": [],
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "for i in sequences:\n",
        "  X.append(i[0:n])\n",
        "  Y.append(i[n])\n",
        "X=np.array(X)\n",
        "Y=np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpmp8tvi7Aat",
        "outputId": "85373317-c448-48f7-a90c-e5f8ab9f26e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs: [[1837 1308  128]\n",
            " [1308  128   32]\n",
            " [ 128   32   13]\n",
            " [  32   13   50]\n",
            " [  13   50  224]\n",
            " [  50  224    1]\n",
            " [ 224    1   10]\n",
            " [   1   10   25]\n",
            " [  10   25  319]\n",
            " [  25  319 1838]\n",
            " [ 319 1838 1605]\n",
            " [1838 1605   92]\n",
            " [1605   92    7]\n",
            " [  92    7 1309]\n",
            " [   7 1309    1]]\n",
            "Outputs: [  32   13   50  224    1   10   25  319 1838 1605   92    7 1309    1\n",
            "   93]\n"
          ]
        }
      ],
      "source": [
        "print(\"Inputs:\",X[:15])\n",
        "print(\"Outputs:\",Y[:15])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gubn7PeV7YpF",
        "outputId": "2aa6934b-be9b-449f-dfad-2a0e7f73b81e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "Y=to_categorical(Y,num_classes=vocab_size,dtype=\"float32\")\n",
        "Y[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYAK1UrB8wSq"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Embedding, LSTM\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,10,input_length=n))\n",
        "model.add(LSTM(1000,return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(vocab_size,activation=\"softmax\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiIr0qgAGVCx",
        "outputId": "7d0ace86-1647-40c4-ffca-d1e2bd743ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             87130     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8713)              8721713   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,857,843\n",
            "Trainable params: 21,857,843\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "brYW0AH3JbRy",
        "outputId": "23e617b9-9712-49aa-fa16-87f9b58fb08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 6.5370 - accuracy: 0.0541\n",
            "Epoch 1: loss improved from inf to 6.53679, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 38s 18ms/step - loss: 6.5368 - accuracy: 0.0541\n",
            "Epoch 2/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 6.0189 - accuracy: 0.0876\n",
            "Epoch 2: loss improved from 6.53679 to 6.01879, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 6.0188 - accuracy: 0.0876\n",
            "Epoch 3/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 5.7018 - accuracy: 0.1029\n",
            "Epoch 3: loss improved from 6.01879 to 5.70170, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 17ms/step - loss: 5.7017 - accuracy: 0.1029\n",
            "Epoch 4/20\n",
            "1756/1758 [============================>.] - ETA: 0s - loss: 5.4501 - accuracy: 0.1146\n",
            "Epoch 4: loss improved from 5.70170 to 5.45020, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 5.4502 - accuracy: 0.1145\n",
            "Epoch 5/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 5.2289 - accuracy: 0.1240\n",
            "Epoch 5: loss improved from 5.45020 to 5.22914, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 5.2291 - accuracy: 0.1240\n",
            "Epoch 6/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 5.0124 - accuracy: 0.1332\n",
            "Epoch 6: loss improved from 5.22914 to 5.01254, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 5.0125 - accuracy: 0.1332\n",
            "Epoch 7/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 4.7912 - accuracy: 0.1409\n",
            "Epoch 7: loss improved from 5.01254 to 4.79103, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 4.7910 - accuracy: 0.1409\n",
            "Epoch 8/20\n",
            "1758/1758 [==============================] - ETA: 0s - loss: 4.5667 - accuracy: 0.1505\n",
            "Epoch 8: loss improved from 4.79103 to 4.56673, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 4.5667 - accuracy: 0.1505\n",
            "Epoch 9/20\n",
            "1758/1758 [==============================] - ETA: 0s - loss: 4.3312 - accuracy: 0.1612\n",
            "Epoch 9: loss improved from 4.56673 to 4.33122, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 4.3312 - accuracy: 0.1612\n",
            "Epoch 10/20\n",
            "1756/1758 [============================>.] - ETA: 0s - loss: 4.0860 - accuracy: 0.1769\n",
            "Epoch 10: loss improved from 4.33122 to 4.08622, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 4.0862 - accuracy: 0.1770\n",
            "Epoch 11/20\n",
            "1756/1758 [============================>.] - ETA: 0s - loss: 3.8314 - accuracy: 0.2016\n",
            "Epoch 11: loss improved from 4.08622 to 3.83123, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 3.8312 - accuracy: 0.2016\n",
            "Epoch 12/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 3.5750 - accuracy: 0.2327\n",
            "Epoch 12: loss improved from 3.83123 to 3.57500, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 17ms/step - loss: 3.5750 - accuracy: 0.2327\n",
            "Epoch 13/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 3.3174 - accuracy: 0.2678\n",
            "Epoch 13: loss improved from 3.57500 to 3.31740, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 3.3174 - accuracy: 0.2679\n",
            "Epoch 14/20\n",
            "1758/1758 [==============================] - ETA: 0s - loss: 3.0601 - accuracy: 0.3045\n",
            "Epoch 14: loss improved from 3.31740 to 3.06007, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 3.0601 - accuracy: 0.3045\n",
            "Epoch 15/20\n",
            "1758/1758 [==============================] - ETA: 0s - loss: 2.7995 - accuracy: 0.3472\n",
            "Epoch 15: loss improved from 3.06007 to 2.79951, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 2.7995 - accuracy: 0.3472\n",
            "Epoch 16/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 2.5395 - accuracy: 0.3932\n",
            "Epoch 16: loss improved from 2.79951 to 2.53953, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 2.5395 - accuracy: 0.3932\n",
            "Epoch 17/20\n",
            "1758/1758 [==============================] - ETA: 0s - loss: 2.2792 - accuracy: 0.4420\n",
            "Epoch 17: loss improved from 2.53953 to 2.27916, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 2.2792 - accuracy: 0.4420\n",
            "Epoch 18/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 2.0296 - accuracy: 0.4925\n",
            "Epoch 18: loss improved from 2.27916 to 2.02962, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 2.0296 - accuracy: 0.4925\n",
            "Epoch 19/20\n",
            "1757/1758 [============================>.] - ETA: 0s - loss: 1.7891 - accuracy: 0.5444\n",
            "Epoch 19: loss improved from 2.02962 to 1.78911, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 18ms/step - loss: 1.7891 - accuracy: 0.5444\n",
            "Epoch 20/20\n",
            "1756/1758 [============================>.] - ETA: 0s - loss: 1.5741 - accuracy: 0.5918\n",
            "Epoch 20: loss improved from 1.78911 to 1.57398, saving model to next_word.h5\n",
            "1758/1758 [==============================] - 31s 17ms/step - loss: 1.5740 - accuracy: 0.5918\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd10ac392e0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "checkpoint=ModelCheckpoint(\"next_word.h5\",monitor='loss',verbose=1,save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "model.fit(X,Y,epochs=20,batch_size=64,callbacks=[checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wK2hWMcK0P9",
        "outputId": "3f4eaf40-92fe-4703-e0c5-45708c3ae71c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3516/3516 [==============================] - 21s 6ms/step - loss: 1.2052\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.205177903175354"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRIWrY06Q-KU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = load_model('next_word.h5')\n",
        "tokenizer = pickle.load(open('aa.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "  \n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "  \n",
        "  print(predicted_word)\n",
        "  return predicted_word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZaJKotF1vGYQ",
        "outputId": "301f44bc-b1de-482a-fc18-d5e44fab084b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'am', 'a']\n",
            "1/1 [==============================] - 1s 805ms/step\n",
            "stupid\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-16-10cbba31caae>\", line 2, in <cell line: 2>\n",
            "    text = input(\"Enter your line: \")\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 851, in raw_input\n",
            "    return self._input_request(str(prompt),\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 895, in _input_request\n",
            "    raise KeyboardInterrupt(\"Interrupted by user\") from None\n",
            "KeyboardInterrupt: Interrupted by user\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 1543, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 1501, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 754, in getmodule\n",
            "    modulesbyfile[f] = modulesbyfile[\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-10cbba31caae>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your line: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "  \n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-3:]\n",
        "          print(text)\n",
        "        \n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "          \n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd2W7xQGvbmI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}